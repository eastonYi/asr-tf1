dirs:
    exp: aishell
    train:
        scp: /mnt/lustre/xushuang2/easton/data/aishell/feats/feats.train-5k.scp
        trans: /mnt/lustre/xushuang2/easton/data/aishell/phone/train-5k.phone67
        tfdata: /mnt/lustre/xushuang2/easton/data/aishell/phone/tfdata/train-5k_xy_eos
    untrain:
        scp: /mnt/lustre/xushuang2/easton/data/aishell/feats/feats.train-10k.scp
        trans: /mnt/lustre/xushuang2/easton/data/aishell/phone/train-10k.phone67
        tfdata: /mnt/lustre/xushuang2/easton/data/aishell/phone/tfdata/train-10k_xy_eos
    # untrain:
    #     scp: /mnt/lustre/xushuang2/easton/data/aishell/feats/feats.train-120k.scp
    #     trans: /mnt/lustre/xushuang2/easton/data/aishell/phone/train-120k.phone67
    #     tfdata: /mnt/lustre/xushuang2/easton/data/aishell/phone/tfdata/train-120k_xy_eos
    dev:
        scp: /mnt/lustre/xushuang2/easton/data/aishell/feats/feats.dev-14k.scp
        trans: /mnt/lustre/xushuang2/easton/data/aishell/phone/dev-14k.phone67
        tfdata: /mnt/lustre/xushuang2/easton/data/aishell/phone/tfdata/dev-14k_xy_eos
    test:
        scp: /mnt/lustre/xushuang2/easton/data/aishell/feats/feats.test-7k.scp
        trans: /mnt/lustre/xushuang2/easton/data/aishell/phone/test-7k.phone67
        tfdata: /mnt/lustre/xushuang2/easton/data/aishell/phone/tfdata/test-7k_xy_eos
    text:
        data: /mnt/lustre/xushuang2/easton/data/aishell/phone/text-120k.phone67
    type: scp
    vocab: /mnt/lustre/xushuang2/easton/data/aishell/phone/phones_67.vocab
    checkpoint_G: /mnt/lustre/xushuang2/easton/projects/asr-tf1/exps/aishell/aishell_transformer_big/train-5k/checkpoint
    # checkpoint: /mnt/lustre/xushuang2/easton/projects/asr-tf1/exps/aishell/aishell_transformer_big/checkpoint

data:
    featType: mfcc
    left_context: 2
    right_context: 0
    downsample: 3
    add_delta: False
    unit: word

model:
    type: transformer
    encoder:
        type: transformer_encoder
        num_blocks: 6
        num_heads: 8
        num_cell_units: 512
        attention_dropout_rate: 0.1
        residual_dropout_rate: 0.1
    decoder:
        type: transformer_decoder
        size_embedding: 512
        num_blocks: 3
        num_heads: 8
        num_cell_units: 512
        attention_dropout_rate: 0.1
        residual_dropout_rate: 0.1
        init_scale: 0.04
        label_smoothing: 0.9
        max_decode_len: 60
model_D:
    type: clm
    num_hidden: 512
    num_blocks: 5

lr_type: constant_learning_rate
optimizer: adam
lr: 0.00001
# warmup_steps: 2000
# peak: 0.0002
# decay_steps: 2000
# warmup_steps: 1000
# peak: 0.0002
# decay_steps: 2000

dev_step: 1000
decode_step: 1000
save_step: 1000
num_epochs: 999

gpus: '0,1,2,3'
# gpus: '0,2,3'
# gpus: '4,5,6,7'
# gpus: '0'
batch_size: 12
beam_size: 1
text_batch_size: 24
max_feat_len: 500
max_label_len: 60
num_batch_tokens: 16000
bucket_boundaries: 102,114,124,134,144,155,166,179,192,209,235,301,410

lambda_lm: 0.0
grad_clip_value: 10.0
grad_clip_norm: 10.0
grad_clip_global_norm: 10.0
