dirs:
    exp: gen_text
    train:
        scp: /mnt/lustre/xushuang2/easton/data/aishell/feats/feats.train-5k.scp
        trans: /mnt/lustre/xushuang2/easton/data/aishell/phone/train-5k.phone67
        tfdata: /mnt/lustre/xushuang2/easton/data/aishell/phone/tfdata/train-5k_xy
    untrain:
        scp: /mnt/lustre/xushuang2/easton/data/aishell/feats/feats.train-120k.scp
        trans: /mnt/lustre/xushuang2/easton/data/aishell/phone/train-120k.phone67
        tfdata: /mnt/lustre/xushuang2/easton/data/aishell/phone/tfdata/train-120k_xy
    dev:
        scp: /mnt/lustre/xushuang2/easton/data/aishell/feats/feats.dev-14k.scp
        trans: /mnt/lustre/xushuang2/easton/data/aishell/phone/dev-14k.phone67
        tfdata: /mnt/lustre/xushuang2/easton/data/aishell/phone/tfdata/dev-14k_xy
    test:
        scp: /mnt/lustre/xushuang2/easton/data/aishell/feats/feats.test-7k.scp
        trans: /mnt/lustre/xushuang2/easton/data/aishell/phone/test-7k.phone67
        tfdata: /mnt/lustre/xushuang2/easton/data/aishell/phone/tfdata/test-7k_xy
    text:
        # data: /mnt/lustre/xushuang2/easton/data/aishell/phone/text-120k.phone67
        data: /home/user/easton/data/AISHELL/phone/text-120k.phone67
        supervise: /home/user/easton/data/AISHELL/phone/text-5k.phone67
        # supervise: /mnt/lustre/xushuang2/easton/data/aishell/phone/text-120k.phone67
        dev: /home/user/easton/data/AISHELL/phone/dev-14k.phone67
    type: test
    # vocab: /mnt/lustre/xushuang2/easton/data/aishell/phone/phones_67+1.vocab
    vocab: /home/user/easton/data/AISHELL/phone/phones_67+1.vocab
    checkpoint_G: /home/user/easton/projects/asr-tf1/exps/gen_text/aishell_phone/checkpoint/model-599
    # checkpoint: /mnt/lustre/xushuang2/easton/projects/asr-tf1/exps/libri/libri_transformer/test2/checkpoint

# data:
#     featType: mfcc
#     left_context: 0
#     right_context: 0
#     downsample: 1
#     add_delta: False
#     unit: word

model:
    type: ctcModel
    num_blocks: 5
    dim_input: 10
    hidden_size: 512
    num_filters: 128
    num_fc: 3
    encoder:
        type: conv2
    decoder:
        type: FC

model_D:
    type: clm
    num_blocks: 5
    hidden_size: 128
    num_fc: 2
    max_feat_len: 1000

noise: 4.0
uprate: 3.0
# lr_type: constant_learning_rate
optimizer: adam
# lr: 0.0001
rate: 0.6
lr_G: 0.0001
lr_D: 0.001
supervise_G_rate: 1.0
warmup_steps: 5000
peak: 0.001
decay_steps: 8000

decode_step: 100
dev_step: 100
save_step: 100
num_epochs: 999

# gpus: '0,1,2,3'
# gpus: '0,1,2,3'
# gpus: '4,5,6,7'
gpus: '0'
batch_size: 160
beam_size: 1
text_batch_size: 100
max_label_len: 20
num_supervised: 1000
num_batch_tokens: 20000
bucket_boundaries: 308,343,373,403,432,465,500,537,578,629,706,905,1230

lambda_lm: 0.0
lambda_l2: 0.0
grad_clip_value: 0.0
grad_clip_norm: 0.0
grad_clip_global_norm: 0.0
