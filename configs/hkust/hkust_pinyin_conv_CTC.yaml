dirs:
    exp: hkust
    train:
    #     scp: /mnt/lustre/xushuang2/easton/data/hkust/feats.train_3x.scp
    #     trans: /mnt/lustre/xushuang2/easton/data/hkust/pinyin.train_3x.scp
    #     tfdata: /mnt/lustre/xushuang2/easton/data/hkust/tfdata/train_pinyin_xy
    # train_supervised:
        scp: /mnt/lustre/xushuang2/easton/data/hkust/feats.train_1k_3x.scp
        trans: /mnt/lustre/xushuang2/easton/data/hkust/pinyin.train_1k_3x.scp
        tfdata: /mnt/lustre/xushuang2/easton/data/hkust/tfdata/train_pinyin_1k_xy
    dev:
        scp: /mnt/lustre/xushuang2/easton/data/hkust/feats.dev.scp
        trans: /mnt/lustre/xushuang2/easton/data/hkust/pinyin.dev.scp
        tfdata: /mnt/lustre/xushuang2/easton/data/hkust/tfdata/dev_pinyin_xy
    test:
        scp: /mnt/lustre/xushuang2/easton/data/hkust/feats.dev.scp
        trans: /mnt/lustre/xushuang2/easton/data/hkust/pinyin.dev.scp
    type: scp
    vocab: /mnt/lustre/xushuang2/easton/data/hkust/pinyin_1385+1.vocab
    # checkpoint: /mnt/lustre/xushuang2/easton/projects/EODM/exps/hksut/hkust_CTC/checkpoint

data:
    featType: mfcc
    left_context: 0
    right_context: 0
    downsample: 1
    add_delta: False
    unit: word

model:
    type: ctcModel
    confidence_penalty: 0.2
    encoder:
        type: conv2
        num_blocks: 3
        num_filters: 512
        dropout: 0.9
    decoder:
        type: FC
        num_fc: 2
        hidden_size: 256
opti:
    type: adam
    lr: 0.0004

dev_step: 200
decode_step: 200
save_step: 200
num_epochs: 999
sample_uttid: 

optimizer: adam
# warmup_steps: 6000
# peak: 0.0002
# decay_steps: 8000
warmup_steps: 1000
peak: 0.0002
decay_steps: 2000

# gpus: '2,3'
gpus: '4,5,6,7'
batch_size: 60
beam_size: 1
text_batch_size: 200
num_supervised:
num_batch_tokens: 100000
bucket_boundaries: 192,262,322,380,444,526,662,1230,4264
seed: 8

lambda_l2: 0.0
grad_clip_value: 0.0
slot_clip_value: 0.0
grad_clip_norm: 0.0
grad_clip_global_norm: 0.0
